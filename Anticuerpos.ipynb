{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold, RepeatedKFold\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler(set):\n",
    "    scaler = StandardScaler()\n",
    "    set = scaler.fit_transform(set)\n",
    "    return set\n",
    "\n",
    "def generating_metrics(model_ehr, x, y):\n",
    "    \"\"\"Function to generate metrics: auc_score, sensitivity, specificity, f1, accuracy\"\"\"\n",
    "    y_pred = model_ehr.predict(x)\n",
    "    acc = accuracy_score(y,y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y,y_pred).ravel()\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y, y_pred)\n",
    "    sensitivity = tp / (tp+fn)\n",
    "    specificity = tn / (tn+fp)\n",
    "    auc_score = auc(false_positive_rate, true_positive_rate)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    return auc_score, sensitivity, specificity, f1, acc, false_positive_rate, true_positive_rate\n",
    "\n",
    "def curvaROC(title, fpr_test, tpr_test, auc_test):\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr_test, tpr_test, label='Testing (AUC=%0.2f)' % auc_test, color='darkorange')\n",
    "    plt.xlabel('1 - Specificity')\n",
    "    plt.ylabel('Sensitivity')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama침o: (46, 12)\n",
      "Index(['id', 'CDR3long', 'N1long', 'N2long', 'NtP3V', 'NtP5D', 'NtP3D',\n",
      "       'NtP5J', 'TamRelCluster', 'CaCo_n', 'IdLG', 'G4_num'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('base_agregada.csv', header=0,na_filter=True)\n",
    "print(\"Tama침o:\", df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separamos en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['id','CaCo_n'],axis = 1)\n",
    "y = df['CaCo_n'].astype(int)\n",
    "y = y.values.reshape(y.shape[0],1)\n",
    "\n",
    "### Utilizando 10 variables\n",
    "X_train_10, X_test_10, y_train_10, y_test_10 = train_test_split(X, y, test_size=0.20,random_state=42)\n",
    "\n",
    "### Utilizando G4_num y TamRelCluster\n",
    "X_2 = df[['TamRelCluster','G4_num']]\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y, test_size=0.20,random_state=42)\n",
    "\n",
    "### Utilizando G4_num, TamRelCluster y CDR3long\n",
    "X_3 = df[['CDR3long','TamRelCluster','G4_num']]\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_3, y, test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definimos los clasificadores y los par치metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_validation = RepeatedKFold(n_splits=3, n_repeats=5, random_state=42)\n",
    "estimator_xgb = xgb.XGBClassifier()\n",
    "parameters={\"n_estimators\": np.arange(50,200,10), \n",
    "            \"learning_rate\": np.arange(0.1,1.0,0.1),\n",
    "            \"colsample_bytree\" : np.arange(0.1,1.0,0.1),\n",
    "            \"subsample\" : np.arange(0.1,1.0,0.1),\n",
    "            \"reg_alpha\" : np.arange(0,20,1), \n",
    "            \"reg_lambda\": np.arange(0,20,1),\n",
    "            \"objective\": ['binary:logistic'],\n",
    "            \"max_depth\": np.arange(0,4,1), \n",
    "            \"gamma\":range(0,5),\n",
    "            \"eval_metric\": ['auc']}\n",
    "\n",
    "randomSearch = RandomizedSearchCV(estimator=estimator_xgb, param_distributions = parameters,\n",
    "                          n_iter=100, scoring='roc_auc',cv=c_validation,random_state=42, refit = True)\n",
    "\n",
    "LR = LogisticRegression()\n",
    "\n",
    "gridSearch = GridSearchCV(estimator=estimator_xgb, param_grid=parameters, cv = c_validation, \n",
    "                    scoring='roc_auc', refit = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaci칩n de modelos\n",
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_rs10: 0.2916666666666667, sens_rs10: 0.25, spec_rs10: 0.3333333333333333, f1_rs10: 0.22222222222222224, acc_rs10: 0.3\n",
      "auc_2rs: 0.5, sens_rs2: 0.5, spec_rs2: 0.5, f1_rs2: 0.4444444444444445, acc_rs2: 0.5\n",
      "auc_rs3: 0.3333333333333333, sens_rs3: 0.5, spec_rs3: 0.16666666666666666, f1_rs3: 0.36363636363636365, acc_rs3: 0.3\n"
     ]
    }
   ],
   "source": [
    "### Con 10 variables\n",
    "model_rs10 = randomSearch.fit(X_train_10,y_train_10)\n",
    "auc_rs10, sens_rs10, spec_rs10, f1_rs10, acc_rs10,fpr_rs10, tpr_rs10 = generating_metrics(model_rs10, X_test_10, y_test_10)\n",
    "print(\"auc_rs10: {}, sens_rs10: {}, spec_rs10: {}, f1_rs10: {}, acc_rs10: {}\".format(auc_rs10, sens_rs10, spec_rs10, f1_rs10, acc_rs10))\n",
    "### Con G4_num y CDR3long\n",
    "model_rs2 = randomSearch.fit(X_train_2,y_train_2)\n",
    "auc_rs2, sens_rs2, spec_rs2, f1_rs2, acc_rs2,fpr_rs2, tpr_rs2 = generating_metrics(model_rs2, X_test_2, y_test_2)\n",
    "print(\"auc_2rs: {}, sens_rs2: {}, spec_rs2: {}, f1_rs2: {}, acc_rs2: {}\".format(auc_rs2, sens_rs2, spec_rs2, f1_rs2, acc_rs2))\n",
    "### Con CDR3long, G4_num y CDR3long\n",
    "model_rs3 = randomSearch.fit(X_train_3,y_train_3)\n",
    "auc_rs3, sens_rs3, spec_rs3, f1_rs3, acc_rs3,fpr_rs3, tpr_rs3 = generating_metrics(model_rs3, X_test_3, y_test_3)\n",
    "print(\"auc_rs3: {}, sens_rs3: {}, spec_rs3: {}, f1_rs3: {}, acc_rs3: {}\".format(auc_rs3, sens_rs3, spec_rs3, f1_rs3, acc_rs3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Con 10 variables\n",
    "model_gs10 = gridSearch.fit(X_train_10,y_train_10)\n",
    "auc_gs10, sens_gs10, spec_gs10, f1_gs10, acc_gs10,fpr_gs10, tpr_gs10 = generating_metrics(model_gs10, X_test_10, y_test_10)\n",
    "print(\"auc_gs10: {}, sens_gs10: {}, spec_gs10: {}, f1_gs10: {}, acc_gs10: {}\".format(auc_gs10, sens_gs10, spec_gs10, f1_gs10, acc_gs10))\n",
    "### Con G4_num y CDR3long\n",
    "model_gs2 = gridSearch.fit(X_train_2,y_train_2)\n",
    "auc_gs2, sens_gs2, spec_gs2, f1_gs2, acc_gs2,fpr_gs2, tpr_gs2 = generating_metrics(model_gs2, X_test_2, y_test_2)\n",
    "print(\"auc_gs2: {}, sens_gs2: {}, spec_gs2: {}, f1_gs2: {}, acc_gs2: {}\".format(auc_gs2, sens_gs2, spec_gs2, f1_gs2, acc_gs2))\n",
    "### Con CDR3long, G4_num y CDR3long\n",
    "model_gs3 = gridSearch.fit(X_train_3,y_train_3)\n",
    "auc_gs3, sens_gs3, spec_gs3, f1_gs3, acc_gs3,fpr_gs3, tpr_gs3 = generating_metrics(model_gs3, X_test_3, y_test_3)\n",
    "print(\"auc_gs3: {}, sens_gs3: {}, spec_gs3: {}, f1_gs3: {}, acc_gs3: {}\".format(auc_gs3, sens_gs3, spec_gs3, f1_gs3, acc_gs3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_xgb10: 0.20833333333333331, sens_xgb10: 0.25, spec_xgb10: 0.16666666666666666, f1_xgb10: 0.2, acc_xgb10: 0.2\n",
      "auc_xgb2: 0.5, sens_xgb2: 0.5, spec_xgb2: 0.5, f1_xgb2: 0.4444444444444445, acc_xgb2: 0.5\n",
      "auc_xgb3: 0.5, sens_xgb3: 0.5, spec_xgb3: 0.5, f1_xgb3: 0.4444444444444445, acc_xgb3: 0.5\n"
     ]
    }
   ],
   "source": [
    "### Con 10 variables\n",
    "model_xgb10 = estimator_xgb.fit(X_train_10,y_train_10)\n",
    "auc_xgb10, sens_xgb10, spec_xgb10, f1_xgb10, acc_xgb10,fpr_xgb10, tpr_xgb10 = generating_metrics(model_xgb10, X_test_10, y_test_10)\n",
    "print(\"auc_xgb10: {}, sens_xgb10: {}, spec_xgb10: {}, f1_xgb10: {}, acc_xgb10: {}\".format(auc_xgb10, sens_xgb10, spec_xgb10, f1_xgb10, acc_xgb10))\n",
    "### Con G4_num y CDR3long\n",
    "model_xgb2 = estimator_xgb.fit(X_train_2,y_train_2)\n",
    "auc_xgb2, sens_xgb2, spec_xgb2, f1_xgb2, acc_xgb2,fpr_xgb2, tpr_xgb2 = generating_metrics(model_xgb2, X_test_2, y_test_2)\n",
    "print(\"auc_xgb2: {}, sens_xgb2: {}, spec_xgb2: {}, f1_xgb2: {}, acc_xgb2: {}\".format(auc_xgb2, sens_xgb2, spec_xgb2, f1_xgb2, acc_xgb2))\n",
    "### Con CDR3long, G4_num y CDR3long\n",
    "model_xgb3 = estimator_xgb.fit(X_train_3,y_train_3)\n",
    "auc_xgb3, sens_xgb3, spec_xgb3, f1_xgb3, acc_xgb3,fpr_xgb3, tpr_xgb3 = generating_metrics(model_xgb3, X_test_3, y_test_3)\n",
    "print(\"auc_xgb3: {}, sens_xgb3: {}, spec_xgb3: {}, f1_xgb3: {}, acc_xgb3: {}\".format(auc_xgb3, sens_xgb3, spec_xgb3, f1_xgb3, acc_xgb3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_lr10: 0.41666666666666663, sens_lr10: 0.5, spec_lr10: 0.3333333333333333, f1_lr10: 0.4, acc_lr10: 0.4\n",
      "auc_lr2: 0.7916666666666667, sens_lr2: 0.75, spec_lr2: 0.8333333333333334, f1_lr2: 0.75, acc_lr2: 0.8\n",
      "auc_lr3: 0.5416666666666667, sens_lr3: 0.75, spec_lr3: 0.3333333333333333, f1_lr3: 0.5454545454545454, acc_lr3: 0.5\n"
     ]
    }
   ],
   "source": [
    "### Con 10 variables\n",
    "model_lr10 = LR.fit(X_train_10,y_train_10)\n",
    "auc_lr10, sens_lr10, spec_lr10, f1_lr10, acc_lr10,fpr_lr10, tpr_lr10 = generating_metrics(model_lr10, X_test_10, y_test_10)\n",
    "print(\"auc_lr10: {}, sens_lr10: {}, spec_lr10: {}, f1_lr10: {}, acc_lr10: {}\".format(auc_lr10, sens_lr10, spec_lr10, f1_lr10, acc_lr10))\n",
    "### Con G4_num y CDR3long\n",
    "model_lr2 = LR.fit(X_train_2,y_train_2)\n",
    "auc_lr2, sens_lr2, spec_lr2, f1_lr2, acc_lr2,fpr_lr2, tpr_lr2 = generating_metrics(model_lr2, X_test_2, y_test_2)\n",
    "print(\"auc_lr2: {}, sens_lr2: {}, spec_lr2: {}, f1_lr2: {}, acc_lr2: {}\".format(auc_lr2, sens_lr2, spec_lr2, f1_lr2, acc_lr2))\n",
    "### Con CDR3long, G4_num y CDR3long\n",
    "model_lr3 = LR.fit(X_train_3,y_train_3)\n",
    "auc_lr3, sens_lr3, spec_lr3, f1_lr3, acc_lr3,fpr_lr3, tpr_lr3 = generating_metrics(model_lr3, X_test_3, y_test_3)\n",
    "print(\"auc_lr3: {}, sens_lr3: {}, spec_lr3: {}, f1_lr3: {}, acc_lr3: {}\".format(auc_lr3, sens_lr3, spec_lr3, f1_lr3, acc_lr3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
